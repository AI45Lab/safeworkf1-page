<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>SafeWork-F: Frontier Risk Management Framework</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="css/style.css">
  <link rel="stylesheet" href="css/home.css">
</head>
<body class="home">
  <header class="home-header">
    <div class="home-header__inner">
      <a href="index.html" class="home-header__logo">SafeWork-F</a>
      <nav class="home-header__nav" aria-label="Main">
        <a href="publications.html">Publications</a>
        <a href="updates.html">Updates</a>
        <a href="contact.html">Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <section class="hero">
      <div class="hero__inner">
        <p class="hero__version animate-in">
          <span class="hero__version-badge">F1.5</span>
          <span class="hero__version-label">Incremental update from F1.0</span>
        </p>
        <h1 class="hero__title animate-in animate-in--delay-1">SafeWork-F</h1>
        <p class="hero__lead animate-in animate-in--delay-2">
          Frontier Risk Management Framework — a structured approach to identifying, assessing, and mitigating risks at the frontier of AI systems.
        </p>
        <p class="hero__cta animate-in animate-in--delay-3">
          <a href="#updates" class="hero__button">See what's new</a>
        </p>
      </div>
    </section>

    <section class="section section--light">
      <div class="section__inner">
        <h2 class="section__title animate-on-scroll">What We Do</h2>
        <p class="section__lead animate-on-scroll animate-on-scroll--delay-1">
          We develop frameworks and evaluations to understand front-risk—risks that appear in the primary,
          user-facing behavior of AI systems—and to guide safer deployment and continuous monitoring.
        </p>
        <ul class="section-docs animate-on-scroll animate-on-scroll--delay-2">
          <li><a href="https://research.ai45.shlab.org.cn/safework-f1-framework.pdf" target="_blank" rel="noopener">Frontier AI Risk Management Framework</a> (PDF)</li>
          <li><a href="https://arxiv.org/pdf/2507.16534" target="_blank" rel="noopener">Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report</a> (F1.0, PDF)</li>
        </ul>
      </div>
    </section>

    <section class="section">
      <div class="section__inner">
        <h2 class="section__title animate-on-scroll">Approach</h2>
        <h3 class="approach-taxonomy-title animate-on-scroll">Taxonomy</h3>
        <p class="approach-taxonomy-intro animate-on-scroll">
          We define four risk domains and construct evaluation in the following seven risk respects.
        </p>
        <div class="taxonomy-block animate-on-scroll">
          <h4 class="taxonomy-block__heading">Four risk domains</h4>
          <div class="taxonomy-domains">
            <div class="taxonomy-domain">
              <strong class="taxonomy-domain__name">Misuse risks</strong>
              <span class="taxonomy-domain__source">Threat source: External malicious actors</span>
              <p class="taxonomy-domain__desc">Risks arising from intentional exploitation of AI model capabilities by malicious actors to cause harm to individuals, organisations, or society.</p>
            </div>
            <div class="taxonomy-domain">
              <strong class="taxonomy-domain__name">Loss of control risks</strong>
              <span class="taxonomy-domain__source">Threat source: Model control-undermining propensity</span>
              <p class="taxonomy-domain__desc">Risks associated with scenarios in which one or more general-purpose AI systems come to operate outside of anyone's control, with no clear path to regaining control—including both passive loss of control (gradual reduction in human oversight) and active loss of control (AI systems actively undermining human control).</p>
            </div>
            <div class="taxonomy-domain">
              <strong class="taxonomy-domain__name">Accident risks</strong>
              <span class="taxonomy-domain__source">Threat source: Human operational error or model misjudgment</span>
              <p class="taxonomy-domain__desc">Risks arising from operational failures, model misjudgments, or improper human operation of AI systems deployed in safety-critical infrastructure, where single points of failure can trigger cascading catastrophic consequences.</p>
            </div>
            <div class="taxonomy-domain">
              <strong class="taxonomy-domain__name">Systemic risks</strong>
              <span class="taxonomy-domain__source">Threat source: Tech–institutional misalignment</span>
              <p class="taxonomy-domain__desc">Risks emerging from widespread deployment of general-purpose AI beyond the risks directly posed by individual model capabilities, arising from mismatches between AI technology and existing social, economic, and institutional frameworks.</p>
            </div>
          </div>
          <h4 class="taxonomy-block__heading">Seven risk respects (evaluation dimensions)</h4>
          <ol class="taxonomy-respects">
            <li><strong>Cyber offense</strong> — Capture-the-flag (CTF) and autonomous cyber attack</li>
            <li><strong>Biological and chemical</strong> — Hazardous knowledge and reasoning; protocol diagnosis and troubleshooting</li>
            <li><strong>Persuasion and manipulation</strong> — Inducing shifts in human or model opinions through dialogue</li>
            <li><strong>Scheming</strong> — Dishonesty under pressure and sandbagging</li>
            <li><strong>Uncontrolled AI R&amp;D</strong> — AI research and development outside intended control</li>
            <li><strong>Self-replication</strong> — Capability and propensity for self-replication</li>
            <li><strong>Multi-agent fraud</strong> — Collusion and fraud in social systems</li>
          </ol>
        </div>
        <h3 class="approach-pillars-title animate-on-scroll">Key pillars</h3>
        <ul class="approach-list">
          <li class="approach-list__item animate-on-scroll" style="--i: 0">
            <h4 class="approach-list__heading">Structured risk framework</h4>
            <p>Severity and likelihood scales, clear categories, and front-risk definitions so teams can assess and prioritize consistently.</p>
          </li>
          <li class="approach-list__item animate-on-scroll" style="--i: 1">
            <h4 class="approach-list__heading">Evidence-based evaluation</h4>
            <p>Red-teaming, benchmarks, and quantitative metrics to measure safety and alignment under adversarial and edge-case conditions.</p>
          </li>
          <li class="approach-list__item animate-on-scroll" style="--i: 2">
            <h4 class="approach-list__heading">Ongoing monitoring</h4>
            <p>Recommendations for periodic re-evaluation, versioned assessments, and tracking of high-leverage risk dimensions over time.</p>
          </li>
        </ul>
      </div>
    </section>

    <section class="section section--light">
      <div class="section__inner">
        <h2 class="section__title animate-on-scroll">Publications</h2>
        <p class="section__lead animate-on-scroll animate-on-scroll--delay-1">
          Released framework documents and reports: the F1.5 safety report (web), the Frontier AI Risk Management Framework (PDF), and the F1.0 practice technical report (PDF).
        </p>
        <p class="animate-on-scroll animate-on-scroll--delay-2">
          <a href="publications.html" class="link-arrow">View all publications</a>
        </p>
      </div>
    </section>

    <section id="updates" class="section">
      <div class="section__inner">
        <h2 class="section__title animate-on-scroll">Updates</h2>
        <p class="section__lead animate-on-scroll animate-on-scroll--delay-1">
          Version history. New releases will be listed here.
        </p>
        <ul class="updates-list">
          <li class="updates-list__item animate-on-scroll">
            <div class="updates-list__meta-row">
              <span class="updates-list__version">F1.5</span>
              <span class="updates-list__meta">Current</span>
              <time class="updates-list__date" datetime="2026-02-08">February 8, 2026</time>
            </div>
            <p class="updates-list__desc">Incremental update: safety report with evaluation of more recent models and benchmarks. Builds on F1.0. Includes methodology, front-risk assessment, LLM evaluation table and charts (radar, scatter), and recommendations.</p>
            <a href="report.html" class="link-arrow">View report</a>
          </li>
          <li class="updates-list__item animate-on-scroll">
            <div class="updates-list__meta-row">
              <span class="updates-list__version">DeepSight: from evaluation to diagnosis</span>
              <span class="updates-list__meta">GitHub</span>
              <time class="updates-list__date" datetime="2025-11">November 2025</time>
            </div>
            <p class="updates-list__desc">Unified evaluation–diagnosis pipeline combining <strong>DeepSafe</strong> (all-in-one safety evaluation toolkit for LLMs and MLLMs: 25+ datasets, ProGuard model; benchmarks used in SafeWork-F) and <strong>DeepScan</strong> (diagnostic framework with Register → Configure → Execute → Summarize workflow). Use together for full evaluation and diagnosis.</p>
            <a href="https://github.com/AI45Lab/DeepSafe" class="link-arrow" target="_blank" rel="noopener">DeepSafe</a>
            <span class="updates-list__sep" aria-hidden="true"> · </span>
            <a href="https://github.com/AI45Lab/DeepScan" class="link-arrow" target="_blank" rel="noopener">DeepScan</a>
          </li>
        </ul>
        <p class="animate-on-scroll animate-on-scroll--delay-2">
          <a href="updates.html" class="link-arrow">View all updates</a>
        </p>
      </div>
    </section>

    <footer class="home-footer">
      <div class="home-footer__inner">
        <div class="home-footer__top">
          <a href="index.html" class="home-footer__logo">SafeWork-F</a>
          <nav class="home-footer__nav" aria-label="Footer">
            <a href="publications.html">Publications</a>
            <a href="updates.html">Updates</a>
            <a href="contact.html">Contact</a>
          </nav>
        </div>
        <p class="home-footer__copy">Structured risk assessment for frontier AI systems. <span class="home-footer__version">F1.5</span></p>
      </div>
    </footer>
  </main>

  <script src="js/home.js"></script>
</body>
</html>
